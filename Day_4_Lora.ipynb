{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Today we are going to imlement LoRA from scratch"
      ],
      "metadata": {
        "id": "Z8AuIFrUa5hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm as tqdm"
      ],
      "metadata": {
        "id": "R2sQH211a4mW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make model deterministic"
      ],
      "metadata": {
        "id": "A8RD00HibuXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "VAWj1JahbFD4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# load eminist train data\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "\n",
        "# load eminist test data\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFd3USP-b4hB",
        "outputId": "8d37295e-b8f6-40f1-ee5a-693faff42bb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 498kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.88MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create neural network to classify the digit"
      ],
      "metadata": {
        "id": "1NJqoTL2czZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RichBoyNet(nn.Module):\n",
        "  def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "    self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "    self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "89x-TpOFcwD-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = RichBoyNet().to(device)"
      ],
      "metadata": {
        "id": "_5CkKSzNd5qG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
        "  cross_el = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "  total_iterations = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    net.train()\n",
        "\n",
        "    loss_sum = 0\n",
        "    num_iterations = 0\n",
        "\n",
        "    data_iterator = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "    if total_iterations_limit is not None:\n",
        "      data_iterator.total = total_iterations_limit\n",
        "\n",
        "    for img, label in data_iterator:\n",
        "      total_iterations += 1\n",
        "      num_iterations += 1\n",
        "\n",
        "      img, label = img.to(device), label.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward pass\n",
        "      outputs = net(img.view(-1, 28*28))\n",
        "      loss = cross_el(outputs, label)\n",
        "\n",
        "      loss_sum += loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      data_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "      if total_iterations_limit is not None and total_iterations > total_iterations_limit:\n",
        "        break\n",
        "\n",
        "\n",
        "train(train_loader, net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkkQ4BJQeJjQ",
        "outputId": "20dbc3ac-b22f-49ea-c969-51ee1db611f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 6000/6000 [00:51<00:00, 115.73it/s, loss=0.449]\n",
            "Epoch 2: 100%|██████████| 6000/6000 [00:49<00:00, 120.82it/s, loss=0.00302]\n",
            "Epoch 3: 100%|██████████| 6000/6000 [00:49<00:00, 120.64it/s, loss=0.29]\n",
            "Epoch 4: 100%|██████████| 6000/6000 [00:51<00:00, 117.62it/s, loss=6.56e-5]\n",
            "Epoch 5: 100%|██████████| 6000/6000 [00:50<00:00, 118.65it/s, loss=0.0127]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_weights = {}\n",
        "for name, param in net.named_parameters():\n",
        "  original_weights[name] = param.clone().detach()"
      ],
      "metadata": {
        "id": "so37E75_hw0V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  wrong_counts = [0 for i in range(10)]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = net(images.view(-1, 28*28))\n",
        "\n",
        "      for idx, i in enumerate(outputs):\n",
        "        if torch.argmax(i) == labels[idx]:\n",
        "          correct += 1\n",
        "        else:\n",
        "          wrong_counts[labels[idx]] += 1\n",
        "        total += 1\n",
        "  print(f\"Accuracy: {round(correct / total, 3)}\")\n",
        "\n",
        "  for i in range(len(wrong_counts)):\n",
        "    print(f\"Worng count of digits {i}: {wrong_counts[i]}\")"
      ],
      "metadata": {
        "id": "hjLoJBrYhCgi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOPM-fbJq-si",
        "outputId": "af9c416a-0489-4634-a4e5-53c52dacd62f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 257.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Worng count of digits 0: 5\n",
            "Worng count of digits 1: 7\n",
            "Worng count of digits 2: 67\n",
            "Worng count of digits 3: 44\n",
            "Worng count of digits 4: 23\n",
            "Worng count of digits 5: 29\n",
            "Worng count of digits 6: 56\n",
            "Worng count of digits 7: 13\n",
            "Worng count of digits 8: 25\n",
            "Worng count of digits 9: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize how many parameters are in the original network, before including the LoRA matrices"
      ],
      "metadata": {
        "id": "MdvHGffRr_0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_parameters_orignal = 0\n",
        "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
        "  total_parameters_orignal += layer.weight.nelement() + layer.bias.nelement()\n",
        "  print(f\"Layer-{index + 1}  W: {layer.weight.nelement()}  B: {layer.bias.nelement()}\")\n",
        "print(f\"Total parameters is {total_parameters_orignal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1cffJm9r7SU",
        "outputId": "64313870-b859-4671-c12b-aea941595861"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer-1  W: 784000  B: 1000\n",
            "Layer-2  W: 2000000  B: 2000\n",
            "Layer-3  W: 20000  B: 10\n",
            "Total parameters is 2807010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### From Paper section 4.1\n",
        "# https://arxiv.org/pdf/2106.09685\n",
        "\n",
        "\n",
        "# We illustrate our reparametrization in Figure 1. We use a random Gaussian initialization for A and\n",
        "# zero for B, so ∆W = BA is zero at the beginning of training. We then scale ∆W x by α\n",
        "# r , where α\n",
        "# is a constant in r. When optimizing with Adam, tuning α is roughly the same as tuning the learning\n",
        "# rate if we scale the initialization appropriately. As a result, we simply set α to the first r we try\n",
        "# and do not tune it. This scaling helps to reduce the need to retune hyperparameters when we vary\n",
        "# r\n",
        "\n",
        "class LoRAParamterization(nn.Module):\n",
        "  def __init__(self, feature_in, feature_out, rank=1, alpha=1, device='cpu'):\n",
        "    super().__init__()\n",
        "    # we use random Gaussian Intialization for A and zero for B\n",
        "\n",
        "    self.lora_A = nn.Parameter(torch.zeros((rank, feature_out)).to(device))\n",
        "    self.lora_B = nn.Parameter(torch.zeros((feature_in, rank)).to(device))\n",
        "    nn.init.normal_(self.lora_A, mean=0, std=1)\n",
        "\n",
        "    self.scale = alpha / rank\n",
        "    self.enabled = True\n",
        "\n",
        "\n",
        "  def forward(self, original_weights):\n",
        "    if self.enabled:\n",
        "      return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
        "    else:\n",
        "      return original_weights\n"
      ],
      "metadata": {
        "id": "9-ErV_GosqYK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.parametrize as parametrize\n",
        "\n",
        "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
        "\n",
        "  # Only add the  parameterization to the weight matrix, ignore the Bias\n",
        "\n",
        "  features_in, features_out = layer.weight.shape\n",
        "  return LoRAParamterization(\n",
        "      features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
        "  )\n",
        "\n",
        "parametrize.register_parametrization(\n",
        "    net.linear1, \"weight\", linear_layer_parameterization(net.linear1, device)\n",
        ")\n",
        "\n",
        "parametrize.register_parametrization(\n",
        "    net.linear2, \"weight\", linear_layer_parameterization(net.linear2, device)\n",
        ")\n",
        "\n",
        "parametrize.register_parametrization(\n",
        "    net.linear3, \"weight\", linear_layer_parameterization(net.linear3, device)\n",
        ")"
      ],
      "metadata": {
        "id": "efas4Uwd1u_o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_disable_lora(enabled=True):\n",
        "  for layer in [net.linear1, net.linear2, net.linear3]:\n",
        "    layer.parametrizations[\"weight\"][0].enabled = enabled"
      ],
      "metadata": {
        "id": "frfiY8N5shfF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the number of parameters added by LoRA"
      ],
      "metadata": {
        "id": "l7sdR5AwirZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_parameters_lora = 0\n",
        "total_parameters_non_lora = 0\n",
        "\n",
        "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
        "  total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
        "  total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
        "  print(f\"layer-{index + 1} W: {layer.weight.shape} B: {layer.bias.shape} lora_A : {layer.parametrizations['weight'][0].lora_A.shape} lora_B: {layer.parametrizations['weight'][0].lora_B.shape}\")\n",
        "\n",
        "\n",
        "assert total_parameters_non_lora == total_parameters_orignal\n",
        "\n",
        "print(f\"Total number of parameters original: {total_parameters_non_lora}\")\n",
        "print(f\"Total number of parameters original + lora: {total_parameters_non_lora + total_parameters_lora}\")\n",
        "print(f\"Total number of parameters add by lora: {total_parameters_lora}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TuZ_E8xihqW",
        "outputId": "465f59bb-f647-46b7-ddc6-0f4e43f1df56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer-1 W: torch.Size([1000, 784]) B: torch.Size([1000]) lora_A : torch.Size([1, 784]) lora_B: torch.Size([1000, 1])\n",
            "layer-2 W: torch.Size([2000, 1000]) B: torch.Size([2000]) lora_A : torch.Size([1, 1000]) lora_B: torch.Size([2000, 1])\n",
            "layer-3 W: torch.Size([10, 2000]) B: torch.Size([10]) lora_A : torch.Size([1, 2000]) lora_B: torch.Size([10, 1])\n",
            "Total number of parameters original: 2807010\n",
            "Total number of parameters original + lora: 2813804\n",
            "Total number of parameters add by lora: 6794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the non-Lora parameters\n",
        "for name, param in net.named_parameters():\n",
        "  if 'lora' not in name:\n",
        "    print(f\"Freezing non-lora parameters {name}\")\n",
        "    param.b=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH_mAhWeohr9",
        "outputId": "012b4b53-99bf-4c7a-ccb3-bbd699b74244"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing non-lora parameters linear1.bias\n",
            "Freezing non-lora parameters linear1.parametrizations.weight.original\n",
            "Freezing non-lora parameters linear2.bias\n",
            "Freezing non-lora parameters linear2.parametrizations.weight.original\n",
            "Freezing non-lora parameters linear3.bias\n",
            "Freezing non-lora parameters linear3.parametrizations.weight.original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader, net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogOWtMZFpIyP",
        "outputId": "bc732175-1d8a-4d35-b442-cd68860d13c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 6000/6000 [00:50<00:00, 117.95it/s, loss=0.00429]\n",
            "Epoch 2: 100%|██████████| 6000/6000 [00:51<00:00, 117.32it/s, loss=9.82e-6]\n",
            "Epoch 3: 100%|██████████| 6000/6000 [00:51<00:00, 115.63it/s, loss=1.28e-5]\n",
            "Epoch 4: 100%|██████████| 6000/6000 [00:51<00:00, 117.48it/s, loss=0.0528]\n",
            "Epoch 5: 100%|██████████| 6000/6000 [00:50<00:00, 117.94it/s, loss=1.25e-6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the LoRA enaled\n",
        "enable_disable_lora(enabled=True)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOChbIYHr93V",
        "outputId": "17c594f6-8cff-44eb-be84-ecf696f8387d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 286.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.981\n",
            "Worng count of digits 0: 10\n",
            "Worng count of digits 1: 10\n",
            "Worng count of digits 2: 28\n",
            "Worng count of digits 3: 20\n",
            "Worng count of digits 4: 16\n",
            "Worng count of digits 5: 19\n",
            "Worng count of digits 6: 24\n",
            "Worng count of digits 7: 22\n",
            "Worng count of digits 8: 18\n",
            "Worng count of digits 9: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the lora disable result must be same as original\n",
        "enable_disable_lora(enabled=False)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQa38BTlsAv4",
        "outputId": "7a983755-d01c-4a49-8fbf-52bbc1d48758"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 305.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Worng count of digits 0: 5\n",
            "Worng count of digits 1: 7\n",
            "Worng count of digits 2: 67\n",
            "Worng count of digits 3: 44\n",
            "Worng count of digits 4: 23\n",
            "Worng count of digits 5: 29\n",
            "Worng count of digits 6: 56\n",
            "Worng count of digits 7: 13\n",
            "Worng count of digits 8: 25\n",
            "Worng count of digits 9: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the frozen parameters are still unchanged by the finetuning\n",
        "\n",
        "assert torch.all(net.linear1.parametrizations.weight.original == net.linear1.weight)\n",
        "assert torch.all(net.linear2.parametrizations.weight.original == net.linear2.weight)\n",
        "assert torch.all(net.linear3.parametrizations.weight.original == net.linear3.weight)"
      ],
      "metadata": {
        "id": "rzXU3aNotbfG"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}